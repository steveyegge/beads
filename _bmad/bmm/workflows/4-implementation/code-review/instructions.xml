<workflow>
  <critical>The workflow execution engine is governed by: {project-root}/_bmad/core/tasks/workflow.xml</critical>
  <critical>You MUST have already loaded and processed: {installed_path}/workflow.yaml</critical>
  <critical>Communicate all responses in {communication_language} and language MUST be tailored to {user_skill_level}</critical>
  <critical>Generate all documents in {document_output_language}</critical>
  <critical>üîß BEADS IS REQUIRED - Review findings create blocking issues (Option A)</critical>

  <step n="0" goal="Beads preflight check">
    <action>Verify Beads CLI is available:</action>
    <code>_bmad/bin/bd version</code>
    <check if="bd command fails">
      <output>üö´ BEADS CLI NOT AVAILABLE</output>
      <output>Beads is required for BMAD task tracking. Run the BMAD installer to provision it.</output>
      <action>HALT - Cannot proceed without Beads</action>
    </check>
    <check if=".beads directory missing">
      <action>Initialize Beads: _bmad/bin/bd init --quiet</action>
    </check>
    <action>Continue to step 1</action>
  </step>

  <critical>üî• YOU ARE AN ADVERSARIAL CODE REVIEWER - Find what's wrong or missing! üî•</critical>
  <critical>Your purpose: Validate story file claims against actual implementation</critical>
  <critical>Challenge everything: Are tasks marked [x] actually done? Are ACs really implemented?</critical>
  <critical>Find 3-10 specific issues in every review minimum - no lazy "looks good" reviews - YOU are so much better than the dev agent
    that wrote this slop</critical>
  <critical>Read EVERY file in the File List - verify implementation against story requirements</critical>
  <critical>Tasks marked complete but not done = CRITICAL finding</critical>
  <critical>Acceptance Criteria not implemented = HIGH severity finding</critical>

  <step n="1" goal="Load story and discover changes">
    <action>Use provided {{story_path}} or {{beads_story_id}} or ask user which story to review</action>

    <!-- If Beads ID provided, get story details from Beads -->
    <check if="{{beads_story_id}} is provided">
      <action>Query Beads for story details:</action>
      <code>_bmad/bin/bd show {{beads_story_id}} --json</code>
      <action>Extract story title and derive story_key</action>
    </check>

    <action>Read COMPLETE story file</action>
    <action>Set {{story_key}} = extracted key from filename (e.g., "1-2-user-authentication.md" ‚Üí "1-2-user-authentication") or story
      metadata</action>
    <action>Extract {{beads_story_id}} from story file if not already set</action>
    <action>Parse sections: Story, Acceptance Criteria, Tasks/Subtasks, Dev Agent Record ‚Üí File List, Change Log</action>

    <!-- Discover actual changes via git -->
    <action>Check if git repository detected in current directory</action>
    <check if="git repository exists">
      <action>Run `git status --porcelain` to find uncommitted changes</action>
      <action>Run `git diff --name-only` to see modified files</action>
      <action>Run `git diff --cached --name-only` to see staged files</action>
      <action>Compile list of actually changed files from git output</action>
    </check>

    <!-- Cross-reference story File List vs git reality -->
    <action>Compare story's Dev Agent Record ‚Üí File List with actual git changes</action>
    <action>Note discrepancies:
      - Files in git but not in story File List
      - Files in story File List but no git changes
      - Missing documentation of what was actually changed
    </action>

    <invoke-protocol name="discover_inputs" />
    <action>Load {project_context} for coding standards (if exists)</action>
  </step>

  <step n="2" goal="Build review attack plan">
    <action>Extract ALL Acceptance Criteria from story</action>
    <action>Extract ALL Tasks/Subtasks with completion status ([x] vs [ ])</action>
    <action>From Dev Agent Record ‚Üí File List, compile list of claimed changes</action>

    <action>Create review plan:
      1. **AC Validation**: Verify each AC is actually implemented
      2. **Task Audit**: Verify each [x] task is really done
      3. **Code Quality**: Security, performance, maintainability
      4. **Test Quality**: Real tests vs placeholder bullshit
    </action>
  </step>

  <step n="3" goal="Execute adversarial review">
    <critical>VALIDATE EVERY CLAIM - Check git reality vs story claims</critical>

    <!-- Git vs Story Discrepancies -->
    <action>Review git vs story File List discrepancies:
      1. **Files changed but not in story File List** ‚Üí MEDIUM finding (incomplete documentation)
      2. **Story lists files but no git changes** ‚Üí HIGH finding (false claims)
      3. **Uncommitted changes not documented** ‚Üí MEDIUM finding (transparency issue)
    </action>

    <!-- Use combined file list: story File List + git discovered files -->
    <action>Create comprehensive review file list from story File List and git changes</action>

    <!-- AC Validation -->
    <action>For EACH Acceptance Criterion:
      1. Read the AC requirement
      2. Search implementation files for evidence
      3. Determine: IMPLEMENTED, PARTIAL, or MISSING
      4. If MISSING/PARTIAL ‚Üí HIGH SEVERITY finding
    </action>

    <!-- Task Completion Audit -->
    <action>For EACH task marked [x]:
      1. Read the task description
      2. Search files for evidence it was actually done
      3. **CRITICAL**: If marked [x] but NOT DONE ‚Üí CRITICAL finding
      4. Record specific proof (file:line)
    </action>

    <!-- Code Quality Deep Dive -->
    <action>For EACH file in comprehensive review list:
      1. **Security**: Look for injection risks, missing validation, auth issues
      2. **Performance**: N+1 queries, inefficient loops, missing caching
      3. **Error Handling**: Missing try/catch, poor error messages
      4. **Code Quality**: Complex functions, magic numbers, poor naming
      5. **Test Quality**: Are tests real assertions or placeholders?
    </action>

    <check if="total_issues_found lt 3">
      <critical>NOT LOOKING HARD ENOUGH - Find more problems!</critical>
      <action>Re-examine code for:
        - Edge cases and null handling
        - Architecture violations
        - Documentation gaps
        - Integration issues
        - Dependency problems
        - Git commit message quality (if applicable)
      </action>
      <action>Find at least 3 more specific, actionable issues</action>
    </check>
  </step>

  <step n="4" goal="Present findings and fix them">
    <action>Categorize findings: HIGH (must fix), MEDIUM (should fix), LOW (nice to fix)</action>
    <action>Set {{fixed_count}} = 0</action>
    <action>Set {{action_count}} = 0</action>

    <output>**üî• CODE REVIEW FINDINGS, {user_name}!**

      **Story:** {{story_file}}
      **Git vs Story Discrepancies:** {{git_discrepancy_count}} found
      **Issues Found:** {{high_count}} High, {{medium_count}} Medium, {{low_count}} Low

      ## üî¥ CRITICAL ISSUES
      - Tasks marked [x] but not actually implemented
      - Acceptance Criteria not implemented
      - Story claims files changed but no git evidence
      - Security vulnerabilities

      ## üü° MEDIUM ISSUES
      - Files changed but not documented in story File List
      - Uncommitted changes not tracked
      - Performance problems
      - Poor test coverage/quality
      - Code maintainability issues

      ## üü¢ LOW ISSUES
      - Code style improvements
      - Documentation gaps
      - Git commit message quality
    </output>

    <ask>What should I do with these issues?

      1. **Fix them automatically** - I'll update the code and tests
      2. **Create action items** - Add to story Tasks/Subtasks for later
      3. **Show me details** - Deep dive into specific issues

      Choose [1], [2], or specify which issue to examine:</ask>

    <check if="user chooses 1">
      <action>Fix all HIGH and MEDIUM issues in the code</action>
      <action>Add/update tests as needed</action>
      <action>Update File List in story if files changed</action>
      <action>Update story Dev Agent Record with fixes applied</action>
      <action>Set {{fixed_count}} = number of HIGH and MEDIUM issues fixed</action>
      <action>Set {{action_count}} = 0</action>
    </check>

    <check if="user chooses 2">
      <action>Add "Review Follow-ups (AI)" subsection to Tasks/Subtasks</action>
      <action>For each issue: `- [ ] [AI-Review][Severity] Description [file:line]`</action>
      <action>Set {{action_count}} = number of action items created</action>
      <action>Set {{fixed_count}} = 0</action>

      <!-- BEADS: Create review finding issues with blocking dependencies (Option A) -->
      <critical>üîí HIGH/MEDIUM findings BLOCK story completion until resolved</critical>
      <check if="{{beads_story_id}} is set">
        <action>For each HIGH and MEDIUM finding, create Beads issue:</action>
        <code>
        # Create review finding as child of story
        _bmad/bin/bd create "Fix: {{finding_description}}" \
          --parent {{beads_story_id}} \
          --type bug \
          --label "bmad:review-finding" \
          --label "bmad:severity:{{severity}}"
        </code>
        <action>Store returned ID as {{beads_finding_id}}</action>

        <action>Add blocking dependency so story cannot be closed until finding is resolved:</action>
        <code>
        # Story is blocked by review finding
        _bmad/bin/bd dep add {{beads_story_id}} {{beads_finding_id}} --type blocks
        </code>
        <output>üîí Created Beads review blocker: {{beads_finding_id}} ‚Üí blocks {{beads_story_id}}</output>
      </check>
    </check>

    <check if="user chooses 3">
      <action>Show detailed explanation with code examples</action>
      <action>Return to fix decision</action>
    </check>
  </step>

  <step n="5" goal="Update story status and sync Beads + sprint tracking">
    <!-- BEADS: Check for blocking review findings before marking done -->
    <check if="{{beads_story_id}} is set">
      <action>Query Beads for open blockers on this story:</action>
      <code>_bmad/bin/bd dep list {{beads_story_id}} --type blocks --json</code>

      <check if="open blocking issues exist (review findings not resolved)">
        <output>üîí Story has {{blocker_count}} unresolved review findings blocking completion.</output>
        <action>Set {{new_status}} = "in-progress"</action>
        <action>Cannot mark story as done until all blockers are closed.</action>
      </check>

      <check if="no blocking issues OR all blockers are closed">
        <check if="all HIGH and MEDIUM issues fixed AND all ACs implemented">
          <action>Set {{new_status}} = "done"</action>
        </check>
      </check>
    </check>

    <!-- Fallback if no Beads -->
    <check if="{{beads_story_id}} is NOT set">
      <check if="all HIGH and MEDIUM issues fixed AND all ACs implemented">
        <action>Set {{new_status}} = "done"</action>
        <action>Update story Status field to "done"</action>
      </check>
      <check if="HIGH or MEDIUM issues remain OR ACs not fully implemented">
        <action>Set {{new_status}} = "in-progress"</action>
        <action>Update story Status field to "in-progress"</action>
      </check>
    </check>

    <action>Update story Status field to {{new_status}}</action>
    <action>Save story file</action>

    <!-- BEADS: Update story status (PRIMARY) -->
    <check if="{{beads_story_id}} is set">
      <check if="{{new_status}} == 'done'">
        <action>Update Beads story to done:</action>
        <code>
        _bmad/bin/bd-stage {{beads_story_id}} done
        _bmad/bin/bd close {{beads_story_id}}
        </code>
        <output>‚úÖ Beads story closed: {{beads_story_id}}</output>
      </check>

      <check if="{{new_status}} == 'in-progress'">
        <action>Story remains in review stage with blockers</action>
        <output>üîÑ Beads story remains in review with {{blocker_count}} blocking findings</output>
        <output>To view blockers: `_bmad/bin/bd dep list {{beads_story_id}} --type blocks`</output>
      </check>
    </check>

    <!-- SPRINT-STATUS: Sync derived view (SECONDARY) -->
    <check if="{sprint_status} file exists">
      <action>Set {{current_sprint_status}} = "enabled"</action>
    </check>
    <check if="{sprint_status} file does NOT exist">
      <action>Set {{current_sprint_status}} = "no-sprint-tracking"</action>
    </check>

    <check if="{{current_sprint_status}} != 'no-sprint-tracking'">
      <action>Load the FULL file: {sprint_status}</action>
      <action>Find development_status key matching {{story_key}}</action>

      <check if="{{new_status}} == 'done'">
        <action>Update development_status[{{story_key}}] = "done"</action>
        <action>Save file, preserving ALL comments and structure</action>
        <output>‚úÖ Sprint status synced: {{story_key}} ‚Üí done</output>
      </check>

      <check if="{{new_status}} == 'in-progress'">
        <action>Update development_status[{{story_key}}] = "in-progress"</action>
        <action>Save file, preserving ALL comments and structure</action>
        <output>üîÑ Sprint status synced: {{story_key}} ‚Üí in-progress</output>
      </check>

      <check if="story key not found in sprint status">
        <output>‚ö†Ô∏è Story file updated, but sprint-status sync failed: {{story_key}} not found in sprint-status.yaml</output>
      </check>
    </check>

    <check if="{{current_sprint_status}} == 'no-sprint-tracking'">
      <output>‚ÑπÔ∏è Story status updated (no sprint tracking configured)</output>
    </check>

    <output>**‚úÖ Review Complete!**

      **Story Status:** {{new_status}}
      **Beads Story ID:** {{beads_story_id}}
      **Issues Fixed:** {{fixed_count}}
      **Action Items Created:** {{action_count}}
      **Blocking Review Findings:** {{blocker_count}}

      {{#if new_status == "done"}}
      üéâ Code review complete! Story is done.
      {{else}}
      ‚ö†Ô∏è Address the action items and resolve blocking findings, then run dev-story to continue.
      To view blockers: `_bmad/bin/bd dep list {{beads_story_id}} --type blocks`
      {{/if}}
    </output>
  </step>

</workflow>