package main

import (
	"context"
	"log/slog"
	"os"
	"os/signal"
	"runtime"
	"time"

	"github.com/steveyegge/beads/internal/config"
	"github.com/steveyegge/beads/internal/rpc"
	"github.com/steveyegge/beads/internal/storage"
)

// DefaultRemoteSyncInterval is the default interval for periodic remote sync.
// Can be overridden via BEADS_REMOTE_SYNC_INTERVAL environment variable.
const DefaultRemoteSyncInterval = 30 * time.Second

// runEventDrivenLoop implements event-driven daemon architecture.
// Replaces polling ticker with reactive event handlers for:
// - File system changes (JSONL modifications)
// - RPC mutations (create, update, delete)
// - Git operations (via hooks, optional)
// - Parent process monitoring (exit if parent dies)
// - Periodic remote sync (to pull updates from other clones)
//
// The remoteSyncInterval parameter controls how often the daemon pulls from
// remote to check for updates from other clones. Use DefaultRemoteSyncInterval
// or configure via BEADS_REMOTE_SYNC_INTERVAL environment variable.
func runEventDrivenLoop(
	ctx context.Context,
	cancel context.CancelFunc,
	server *rpc.Server,
	serverErrChan chan error,
	store storage.Storage,
	jsonlPath string,
	doExport func(),
	doAutoImport func(),
	autoPull bool,
	parentPID int,
	log *slog.Logger,
) {
	sigChan := make(chan os.Signal, 1)
	signal.Notify(sigChan, daemonSignals...)
	defer signal.Stop(sigChan)

	// Debounced sync actions
	exportDebouncer := NewDebouncer(500*time.Millisecond, func() {
		log.Info("Export triggered by mutation events")
		doExport()
	})
	defer exportDebouncer.CancelAndWait()

	importDebouncer := NewDebouncer(500*time.Millisecond, func() {
		log.Info("Import triggered by file change")
		doAutoImport()
	})
	defer importDebouncer.CancelAndWait()

	// Start file watcher for JSONL changes
	watcher, err := NewFileWatcher(jsonlPath, func() {
		importDebouncer.Trigger()
	})
	var fallbackTicker *time.Ticker
	if err != nil {
		log.Info("WARNING: File watcher unavailable, using 60s polling fallback", "error", err)
		watcher = nil
		// Fallback ticker to check for remote changes when watcher unavailable
		fallbackTicker = time.NewTicker(60 * time.Second)
		defer fallbackTicker.Stop()
	} else {
		watcher.Start(ctx, log)
		defer func() { _ = watcher.Close() }()
	}

	// Handle mutation events from RPC server
	mutationChan := server.MutationChan()
	go func() {
		for {
			select {
			case event, ok := <-mutationChan:
				if !ok {
					// Channel closed (should never happen, but handle defensively)
					log.Info("Mutation channel closed; exiting listener")
					return
				}
				log.Info("Mutation detected", "type", event.Type, "issue_id", event.IssueID)
				exportDebouncer.Trigger()

			case <-ctx.Done():
				return
			}
		}
	}()

	// Periodic health check
	healthTicker := time.NewTicker(60 * time.Second)
	defer healthTicker.Stop()

	// Periodic remote sync to pull updates from other clones
	// This is essential for multi-clone workflows where the file watcher only
	// sees local changes but remote may have updates from other clones.
	// Default is 30 seconds; configurable via BEADS_REMOTE_SYNC_INTERVAL.
	// Only enabled when autoPull is true (default when sync.branch is configured).
	var remoteSyncTicker *time.Ticker
	if autoPull {
		remoteSyncInterval := getRemoteSyncInterval(log)
		if remoteSyncInterval > 0 {
			remoteSyncTicker = time.NewTicker(remoteSyncInterval)
			defer remoteSyncTicker.Stop()
			log.Info("Auto-pull enabled: checking remote periodically", "interval", remoteSyncInterval)
		} else {
			log.Info("Auto-pull disabled: remote-sync-interval is 0")
		}
	} else {
		log.Info("Auto-pull disabled: use 'git pull' manually to sync remote changes")
	}

	// Parent process check (every 10 seconds)
	parentCheckTicker := time.NewTicker(10 * time.Second)
	defer parentCheckTicker.Stop()

	// Dropped events safety net (faster recovery than health check)
	droppedEventsTicker := time.NewTicker(1 * time.Second)
	defer droppedEventsTicker.Stop()

	// Pre-allocate ticker channels to avoid creating new channels on every
	// select iteration. A nil channel blocks forever in select, which is the
	// desired behavior when the corresponding ticker is disabled.
	var remoteSyncChan <-chan time.Time
	if remoteSyncTicker != nil {
		remoteSyncChan = remoteSyncTicker.C
	}
	var fallbackChan <-chan time.Time
	if fallbackTicker != nil {
		fallbackChan = fallbackTicker.C
	}

	for {
		select {
		case <-droppedEventsTicker.C:
			// Check for dropped mutation events every second
			dropped := server.ResetDroppedEventsCount()
			if dropped > 0 {
				log.Info("WARNING: mutation events were dropped, triggering export", "count", dropped)
				exportDebouncer.Trigger()
			}

		case <-healthTicker.C:
			// Periodic health validation (not sync)
			checkDaemonHealth(ctx, store, log)

		case <-remoteSyncChan:
			// Periodic remote sync to pull updates from other clones
			// This ensures the daemon sees changes pushed by other clones
			// even when the local file watcher doesn't trigger
			log.Info("Periodic remote sync: checking for updates")
			doAutoImport()

		case <-parentCheckTicker.C:
			// Check if parent process is still alive
			if !checkParentProcessAlive(parentPID) {
				log.Info("Parent process died, shutting down daemon", "pid", parentPID)
				cancel()
				if err := server.Stop(); err != nil {
					log.Info("Error stopping server", "error", err)
				}
				return
			}

		case <-fallbackChan:
			log.Info("Fallback ticker: checking for remote changes")
			importDebouncer.Trigger()

		case sig := <-sigChan:
			if isReloadSignal(sig) {
				log.Info("Received reload signal, ignoring")
				continue
			}
			log.Info("Received signal, shutting down...", "signal", sig)
			cancel()
			if err := server.Stop(); err != nil {
				log.Info("Error stopping server", "error", err)
			}
			return

		case <-ctx.Done():
			log.Info("Context canceled, shutting down")
			if watcher != nil {
				_ = watcher.Close()
			}
			if err := server.Stop(); err != nil {
				log.Info("Error stopping server", "error", err)
			}
			return

		case err := <-serverErrChan:
			log.Info("RPC server failed", "error", err)
			cancel()
			if watcher != nil {
				_ = watcher.Close()
			}
			if stopErr := server.Stop(); stopErr != nil {
				log.Info("Error stopping server", "error", stopErr)
			}
			return
		}
	}
}

// checkDaemonHealth performs periodic health validation.
// Separate from sync operations - just validates state.
func checkDaemonHealth(ctx context.Context, store storage.Storage, log *slog.Logger) {
	// Health check 1: Verify metadata is accessible
	// This helps detect if external operations (like bd import --force) have modified metadata
	// Without this, daemon may continue operating with stale metadata cache
	// Try new key first, fall back to old for migration
	if _, err := store.GetMetadata(ctx, "jsonl_content_hash"); err != nil {
		if _, err := store.GetMetadata(ctx, "last_import_hash"); err != nil {
			log.Info("Health check: metadata read failed", "error", err)
			// Non-fatal: daemon continues but logs the issue
			// This helps diagnose stuck states in sandboxed environments
		}
	}

	// Health check 2: Database integrity check
	// Verify the database is accessible and structurally sound
	if db := store.UnderlyingDB(); db != nil {
		// Quick integrity check - just verify we can query
		var result string
		if err := db.QueryRowContext(ctx, "PRAGMA quick_check(1)").Scan(&result); err != nil {
			log.Info("Health check: database integrity check failed", "error", err)
		} else if result != "ok" {
			log.Info("Health check: database integrity issue", "result", result)
		}
	}

	// Health check 3: Disk space check (platform-specific)
	// Uses checkDiskSpace helper which is implemented per-platform
	dbPath := store.Path()
	if dbPath != "" {
		if availableMB, ok := checkDiskSpace(dbPath); ok {
			// Warn if less than 100MB available
			if availableMB < 100 {
				log.Info("Health check: low disk space warning", "available_mb", availableMB)
			}
		}
	}

	// Health check 4: Memory usage check
	// Log warning if memory usage is unusually high
	var memStats runtime.MemStats
	runtime.ReadMemStats(&memStats)
	heapMB := memStats.HeapAlloc / (1024 * 1024)

	// Warn if heap exceeds 500MB (daemon should be lightweight)
	if heapMB > 500 {
		log.Info("Health check: high memory usage warning", "heap_mb", heapMB)
	}
}

// getRemoteSyncInterval returns the interval for periodic remote sync.
// Configuration sources (in order of precedence):
//  1. BEADS_REMOTE_SYNC_INTERVAL environment variable
//  2. remote-sync-interval in .beads/config.yaml
//  3. DefaultRemoteSyncInterval (30s)
//
// Accepts Go duration strings like:
// - "30s" (30 seconds)
// - "1m" (1 minute)
// - "5m" (5 minutes)
// - "0" or "0s" (disables periodic sync - use with caution)
//
// Minimum allowed value is 5 seconds to prevent excessive load.
func getRemoteSyncInterval(log *slog.Logger) time.Duration {
	// config.GetDuration handles both config.yaml and env var (env takes precedence)
	duration := config.GetDuration("remote-sync-interval")

	// If config returns 0, it could mean:
	// 1. User explicitly set "0" to disable
	// 2. Config not found (use default)
	// Check if there's an explicit value set
	if duration == 0 {
		// Check if user explicitly set it to 0 via env var
		if envVal := os.Getenv("BEADS_REMOTE_SYNC_INTERVAL"); envVal == "0" || envVal == "0s" {
			log.Info("Warning: remote-sync-interval is 0, periodic remote sync disabled")
			return 24 * time.Hour * 365
		}
		// Otherwise use default
		return DefaultRemoteSyncInterval
	}

	// Minimum 5 seconds to prevent excessive load
	if duration > 0 && duration < 5*time.Second {
		log.Info("Warning: remote-sync-interval too low, using minimum 5s", "duration", duration)
		return 5 * time.Second
	}

	// Log if using non-default value
	if duration != DefaultRemoteSyncInterval {
		log.Info("Using custom remote sync interval", "interval", duration)
	}
	return duration
}
